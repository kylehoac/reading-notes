# Reading Notes 13 Course 401

## Linear Regression

__*Scikit Learn*__

A python module for machine learning. Contains regression, classification, clustering, model selection, and dimensionality reduction.

Important functions for fitting a linear regression model:

- .fit() - Fits a linear model

- .predict() - Predict Y using the linear model with estimated coefficients

- .score() - Returns the coefficient of "determination" (R^2).(Measures how well observed outcomes are replicated by a model, as the proportion of total variation of outcomes explained by the model)

- .coef_ - Gives the estimated coefficients

- .intercept_ - Gives estimated intercepts

__*Fitting a linear model*__

Two parameters that are passed into a linear regression object are:

- fit_intercept - Whether to calculate the intercept for specific model. Defaults to True

- normalize - If true, the regressors X will be normalized before regressors X Ignored when fit_intercept is set to false

__*Training and validation data sets*__

Instead of implementing linear regression on the entire data set, you split the data sets into training and test sets

- To divide your training sets randomly, Scikit provides a function called "train_test_split"
 
__*Residual Plots*__

Residual plots provide a good way to visualize errors in your data

- A good data set should be randomly scattered around line zero

- If there is structure in your data, that means your model is not capturing something

[<== Back to Main Page](README.md)
